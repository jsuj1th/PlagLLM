# PlagLLM
PlagLLM is a tool for classifying text as either human-written or generated by a Large Language Model (LLM). It leverages the LIME (Local Interpretable Model-agnostic Explanations) framework to provide interpretable explanations for its predictions.

## Features

- Detects whether input text is human or LLM generated
- Uses LIME for model interpretability
- Easy-to-use interface for classification and explanation

## Installation

```bash
git clone https://github.com/yourusername/PlagLLM.git
cd PlagLLM
pip install -r requirements.txt
```

## Usage

```python
from plagllm import classify_text, explain_prediction

text = "Your input text here."
label = classify_text(text)
explanation = explain_prediction(text)

print(f"Predicted label: {label}")
print(explanation)
```

## How It Works

PlagLLM uses a trained classifier to distinguish between human and LLM-generated text. LIME is integrated to highlight which parts of the text influenced the prediction, helping users understand the model's decision.

## License

This project is licensed under the MIT License.